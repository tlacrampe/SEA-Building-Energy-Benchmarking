---
title: "DecisionTree-SEA-building-energy-bechmarking"
author: "Christopher Lacrampe"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:

    code_folding: show
    highlight: tango
    theme: yeti
    toc: yes
    toc_depth: 5
    toc_float: yes
---

The aim of this predictive model is to be able to classify buildings on the basis of being able to obtain Energy Star Certification (Energy Star Score >= 75). By training a Decision Tree, we can classify other buildings in the Seattle area that have not enrolled in the energy star program, but have access to the same variables as our training and test sets.

# 1. Loading, cleaning, and preparing the data/libraries

### 1.1 Loading libraries and datasets

```{r}
library(gmodels) # useful library for CrossTabs/confusion matrices
library(C50) # has the C5.0 method used to train the decision tree model
library(tidyverse) # has useful libraries for cleaning and filtering data
energyDat2016 = read.csv("sea-building-energy-benchmarking/2015-building-energy-benchmarking.csv", stringsAsFactors = FALSE)
```

### 1.2 Cleaning the data

#### 1.2.1 Removing outliers
Our dataset has come prepared with an **Outlier** feature where the data controller has flagged outliers as "High" and "Low", we will remove those outliers

```{r}
energyDat2016 = tbl_df(filter(energyDat2016, Outlier == ""))
energyDat2016 = as.data.frame(energyDat2016)
```

#### 1.2.2 Create class variable from the Energy Star Score (Good = ENERGYSTARScore > 75, Bad = otherwise as per EnergyStar certification guidelines)

```{r}
StarScore = ifelse(energyDat2016$ENERGYSTARScore >= 75, "Good", "Bad")
energyDat2016$StarScore = StarScore
energyDat2016$StarScore = as.factor(energyDat2016$StarScore)
```

#### 1.2.3 Create a dataframe utilizing the variables we want to include in our model (this strips redundant variables that are identical to the others just measured in different units)

```{r}
modelDat = select(energyDat2016, StarScore, YearBuilt, PropertyGFATotal, SiteEUIWN.kBtu.sf., Electricity.kBtu., NaturalGas.kBtu., GHGEmissionsIntensity.kgCO2e.ft2.)
# remove NA values
modelDat = na.omit(modelDat)
```

# 2. Splitting the data and training the model

#### 2.1 Splitting the dataset

```{r}
# randomize the entries and split into training and test
set.seed(123)
mod_rand = order(runif(2491))

# split the randomized set into a training set and test set
mod_train = modelDat[mod_rand[1:2000],]
mod_test = modelDat[mod_rand[2000:2491],]

# store the target variable as seperate vectors
mod_train_labels = as.factor(as.vector(mod_train$StarScore))
mod_test_labels = as.factor(as.vector(mod_test$StarScore))

```

#### 2.2 Training the model using C5.0 algorithm

```{r}
energy_model = C5.0(mod_train[-1], mod_train$StarScore)
energy_model
```

##### 2.2.1 Explain the results of the training model

We can see that our tree is 16 decisions deep (16 possible paths), using 6 features and 2000 observation.

##### 2.2.2 Graphing the tree

```{r}
summary(energy_model)
```

From this output, we can walk through the decision tree by following the different paths (the tree is represented left to right, with the root on the top left). For instance, from the top we can see the initial node is based on British thermal units per square foot of the space being greater than 62.6.  

At the bottom of the model, we can see a confusion matrix. The error rate is given as 24.5% (490 times), with 289 false positives and 201 false negatives. 

##### 2.2.3 Evaluating model performance

###### 2.2.3.1 Use the energy_model to predict on the test set

```{r}
energy_pred = predict(energy_model, mod_test)
```

###### 2.2.3.2 Use a cross-tab to evaluate the model's performance

```{r}
CrossTable(mod_test$StarScore, energy_pred,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual', 'predicted'))
```

###### 2.2.3.3 Explain the results. Is this model a good model?

From the CrossTable() we can see our model has an accuracy of (156+222/492) = 76.8%. This model also had 39 false negatives and 75 false positives. The false positive numbers are bad for our results, as they indicate responses the model would classify as "Good" energy efficient buildings when in actuality they would be "bad". We can improve upon our model by penalizing the false-positive predictions in the next sections.

# 3. Improving the model performance

#### 3.1.1. Use adaptive boosting methods to improve the accuracy of the previous decision tree
We will boost with 10 trials as recommended by the publishers of the C5.0 algorithm (this often reduces the number of errors by up to 25%)

```{r}
energy_boost10 = C5.0(mod_train[-1], mod_train$StarScore, trials = 10)
energy_boost10
```

From this output, we can see that the average tree size has shrunk to 6.9 possible decisions from the original tree of 16 decisions.

#### 3.1.2 Use the energy_boost10 to generate predictions

```{r}
energy_boost_pred10 = predict(energy_boost10, mod_test)
```

#### 3.2.3 Evaluate the model results

```{r}
CrossTable(mod_test$StarScore, energy_boost_pred10,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual','predicted'))
```

This model has an accuracy of (159+218)/492 = 76.6%. Which is a .2% reduction in accuracy. We have 72 false positives (a reduction of 3 from the previous model) and 43 false negatives (an increase of 4 from the previous model). Overall, the reduction of false-positives with the minor reduction in accuracy could make this model preferred over the original.

#### 3.2.1 Use a cost method to penalize the false positive errors

```{r}
matrix_dimensions = list(c('Bad', 'Good'), c('Bad', 'Good'))
names(matrix_dimensions) = c('predicted', 'actual')
matrix_dimensions

error_cost = matrix(c(0,4,1,0),nrow = 2,
                    dimnames = matrix_dimensions)
error_cost

energy_cost = C5.0(mod_train[-1], mod_train$StarScore,
                   costs = error_cost)

summary(energy_cost)
```

#### 3.2.2 Are the predictions of this model better? Explain

```{r}
energy_cost_pred = predict(energy_cost, mod_test)
CrossTable(mod_test$StarScore, energy_cost_pred,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual', 'predicted'))
```

This model's accuracy has been reduced to (207 + 88)/492 = 59.96%. However, the false-positive errors have fallen drastically from 72 to 24. In exchange, the false-negatives have increased to a large count of 173. While the false-positives are less desirable for our application, the harsh polarization in accuracy and false-negative rates make this model less desirable than the others. For our purposes, the boosted model would be the best choice of the three.
