---
title: "KNN-SEA-building-energy-bechmarking"
author: "Christopher Lacrampe"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:

    code_folding: show
    highlight: tango
    theme: yeti
    toc: yes
    toc_depth: 4
    toc_float: yes
---

The aim of this predictive model is to be able to classify buildings on the basis of being able to obtain Energy Star Certification (Energy Star Score >= 75). By training a K Nearest Neighbors model, we can classify other buildings in the Seattle area that have not enrolled in the energy star program, but have access to the same variables as our training and test sets.

# 1. Loading, cleaning, and preparing the data/libraries

### 1.1 Loading libraries and datasets

```{r}
library(gmodels) # useful library for CrossTabs/confusion matrices
library(class) # has a knn function used to train the model
library(tidyverse) # has useful libraries for cleaning and filtering data
energyDat2016 = read.csv("sea-building-energy-benchmarking/2015-building-energy-benchmarking.csv", stringsAsFactors = FALSE)
```

### 1.2 Cleaning the data

#### 1.2.1 Removing outliers
Our dataset has come prepared with an **Outlier** feature where the data controller has flagged outliers as "High" and "Low", we will remove those outliers

```{r}
energyDat2016 = tbl_df(filter(energyDat2016, Outlier == ""))
energyDat2016 = as.data.frame(energyDat2016)
```

#### 1.2.2 Create class variable from the Energy Star Score (Good = ENERGYSTARScore > 75, Bad = otherwise as per EnergyStar certification guidelines)

```{r}
StarScore = ifelse(energyDat2016$ENERGYSTARScore >= 75, "Good", "Bad")
energyDat2016$StarScore = StarScore
energyDat2016$StarScore = as.factor(energyDat2016$StarScore)
```

#### 1.2.3 Create a dataframe utilizing the numerical variables we want to include in our KNN model

```{r}
modelDat = select(energyDat2016, StarScore, YearBuilt, PropertyGFATotal, SiteEUIWN.kBtu.sf., Electricity.kBtu., NaturalGas.kBtu., GHGEmissionsIntensity.kgCO2e.ft2.)
# remove NA values
modelDat = na.omit(modelDat)
```

# 2. Transformation - normalizing numeric data

#### 2.1 Create the normalize() function
```{r}
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x))) }
```

#### 2.2 Apply the normlize function to the data

```{r}
normalizedModelDat = as.data.frame(lapply(modelDat[2:7], normalize))
```

#### 2.3 Check if the normalize function worked properly

```{r}
summary(modelDat$YearBuilt)
summary(normalizedModelDat$YearBuilt)
```

We can see that the YearBuilt vector was successfully normalized between 0-1.

# 3. Splitting the data and training the model

#### 3.1 Splitting the dataset

```{r}
# add the result vector back before randomizing
normalizedModelDat$StarScore = modelDat$StarScore
set.seed(123)
mod_rand = order(runif(2491))
mod_train = normalizedModelDat[mod_rand[1:2000],]
mod_test = normalizedModelDat[mod_rand[2000:2491],]

# store the target variable as seperate vectors
mod_train_labels = as.vector(mod_train$StarScore)
mod_test_labels = as.vector(mod_test$StarScore)
mod_train = mod_train[1:6]
mod_test = mod_test[1:6]
```

#### 3.2 Training a model on the data

```{r}
mod_test_pred = knn(train = mod_train,test = mod_test,cl = mod_train_labels,k=5)
```

#### 3.3 Evaluating model Performance

```{r}
CrossTable(x = mod_test_labels, y = mod_test_pred, prop.chisq = FALSE)
Accuracy = (145 + 179)/492
Accuracy
Recall = 179 / (179 + 82)
Recall
Precision = 179/(179 + 86)
Precision
FalsePos = 86/179
FalsePos
FalseNeg = 82/145
FalseNeg
```

Our model accuracy is 65.9%, our model recall is 68.6%, and our model precision = 67.54%.

Our model has a false-positive rate of 48% and a false-negative rate of 56.6%. 


# 4. Improving model performance

### 4.1 Z-score normalization

#### 4.1.1 Normalize the model data using z-score

```{r}
modelDatZ = as.data.frame(scale(modelDat[-1]))
```

#### 4.1.2 Recompose the test and training sets

```{r}
# add the result vector back before randomizing
modelDatZ$StarScore = modelDat$StarScore


set.seed(123)
mod_rand = order(runif(2491))
mod_train = modelDatZ[mod_rand[1:2000],]
mod_test = modelDatZ[mod_rand[2000:2491],]

# store the target variable as seperate vectors
mod_train_labels = as.vector(mod_train$StarScore)
mod_test_labels = as.vector(mod_test$StarScore)
mod_train = mod_train[1:6]
mod_test = mod_test[1:6]
```

#### 4.1.3 Re-train the model

```{r}
mod_test_pred = knn(train = mod_train,test = mod_test,cl = mod_train_labels,k=5)
```

#### 4.1.4 Compare model results
```{r}
CrossTable(x = mod_test_labels, y = mod_test_pred, prop.chisq = FALSE)
Accuracy = (151 + 200)/492
Accuracy
Recall = 200 / (200 + 61)
Recall
Precision = 200/(200 + 80)
Precision
FalsePos = 80/200
FalsePos
FalseNeg = 61/151
FalseNeg
```

Our new model accuracy is 71.3%, our new model recall is 76.6%, and our new model precision = 71.4%.

Our model has a new false-positive rate of 40% and a new false-negative rate of 40.3%. 

Overall, our model improved in accuracy, recall, and precision, while decreasing the false-positive and false-negative rates.

#### 4.1.5 Utilizing a smaller K
Let's adjust our k from 5 to 3 and see if there is an impact on performance

```{r}
mod_test_pred = knn(train = mod_train,test = mod_test,cl = mod_train_labels,k=3)

CrossTable(x = mod_test_labels, y = mod_test_pred, prop.chisq = FALSE)
Accuracy = (147 + 189)/492
Accuracy
Recall = 189 / (189 + 72)
Recall
Precision = 189/(189 + 84)
Precision
FalsePos = 84/189
FalsePos
FalseNeg = 72/147
FalseNeg
```

Overall, decreasing our K yields a reduction in model performance, with accuracy falling to 68.3%, recall falling to 72.4%, precision falling to 69.2%, false-positive rate increasing to 44%, and false-negative rate increasing to 49%.  

#### 4.1.6 Utilizing a larger K

Let's adjust our k from 5 to 7 and see if there is an impact on performance

```{r}
mod_test_pred = knn(train = mod_train,test = mod_test,cl = mod_train_labels,k=7)

CrossTable(x = mod_test_labels, y = mod_test_pred, prop.chisq = FALSE)
Accuracy = (147 + 204)/492
Accuracy
Recall = 204 / (204 + 57)
Recall
Precision = 204/(204 + 78)
Precision
FalsePos = 78/204
FalsePos
FalseNeg = 57/153
FalseNeg
```

This model (k=7) performs the best out of the 4 models we've tested. This model has the highest accuracy (71.3%), recall (78.2%), precision (72.3%) while also having the lowest false-positive rate (38.2%) and lowest false-negative rate (37.3%).

