---
title: "NaiveBayes-SEA-building-energy-bechmarking"
author: "Christopher Lacrampe"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:

    code_folding: show
    highlight: tango
    theme: yeti
    toc: yes
    toc_depth: 4
    toc_float: yes
---

The aim of this predictive model is to be able to classify buildings on the basis of being able to obtain Energy Star Certification (Energy Star Score >= 75). By training a Naive Bayes probabilistic model, we can classify other buildings in the Seattle area that have not enrolled in the energy star program, but have access to the same variables as our training and test sets.

# 1. Loading, cleaning, and preparing the data/libraries

### 1.1 Loading libraries and datasets

```{r}
library(gmodels) # useful library for CrossTabs/confusion matrices
library(e1071) # has a naiveBayes() function used to train the model
library(tidyverse) # has useful libraries for cleaning and filtering data
energyDat2016 = read.csv("sea-building-energy-benchmarking/2015-building-energy-benchmarking.csv", stringsAsFactors = FALSE)
```

### 1.2 Cleaning the data

#### 1.2.1 Removing outliers
Our dataset has come prepared with an **Outlier** feature where the data controller has flagged outliers as "High" and "Low", we will remove those outliers

```{r}
energyDat2016 = tbl_df(filter(energyDat2016, Outlier == ""))
energyDat2016 = as.data.frame(energyDat2016)
```

#### 1.2.2 Create class variable from the Energy Star Score (Good = ENERGYSTARScore > 75, Bad = otherwise as per EnergyStar certification guidelines)

```{r}
StarScore = ifelse(energyDat2016$ENERGYSTARScore >= 75, "Good", "Bad")
energyDat2016$StarScore = StarScore
energyDat2016$StarScore = as.factor(energyDat2016$StarScore)
```

#### 1.2.3 Create a dataframe utilizing the numerical variables we want to include in our NaiveBayes model

```{r}
modelDat = select(energyDat2016, StarScore, YearBuilt, PropertyGFATotal, SiteEUIWN.kBtu.sf., Electricity.kBtu., NaturalGas.kBtu., GHGEmissionsIntensity.kgCO2e.ft2.)
# remove NA values
modelDat = na.omit(modelDat)
```

## 2. Splitting the data and training the model

#### 2.1 Splitting the dataset

```{r}
# add the result vector back before randomizing
set.seed(123)
mod_rand = order(runif(2491))
mod_train = modelDat[mod_rand[1:2000],]
mod_test = modelDat[mod_rand[2000:2491],]

# store the target variable as seperate vectors
mod_train_labels = as.factor(as.vector(mod_train$StarScore))
mod_test_labels = as.factor(as.vector(mod_test$StarScore))
mod_train = mod_train[2:7]
mod_test = mod_test[2:7]
```

#### 2.2 Training the NaiveBayes classifier on the test data

```{r}
naiveBayesMod = naiveBayes(mod_train, mod_train_labels)
```

#### 2.3 Evaluating model performance

```{r}
mod_test_pred = predict(naiveBayesMod, mod_test)
CrossTable(mod_test_pred, mod_test_labels,
           prop.chisq=FALSE,prop.t=FALSE,prop.r=FALSE,
           dnn=c('predicted','actual'))
```

In this cross table, we find an accuracy of ```{r}(47+251)/492``` or 60.6%. We have a ```{r}184/(184+47)``` or 79.7% false-negative rate and a ```{r}10/(10+251)``` or 3.8% false-positive rate as well. The extremely high false-negative rate is alarming, as this would result in an energy-star score for buildings that would exclude them from becoming energy star certified when in actuality they would meet the requirements.

# 4. Improving model performance

#### 4.1 Rebuilding the classifier but setting laplace = 1, and makeing new predictions

```{r}
naiveBayesClassifier = naiveBayes(mod_train, mod_train_labels, laplace = 1)
mod_test_pred = predict(naiveBayesClassifier, mod_test)
```

#### 4.2 Evaluate the results. Did the Laplace estimator improve the results of the Naive Bayes classifier?

```{r}
CrossTable(mod_test_pred, mod_test_labels,
           prop.chisq=FALSE,prop.t=FALSE,prop.r=FALSE,
           dnn=c('predicted','actual'))
```

Comparing this cross-table to the originals, we can see that there is no performance increase from including the laplace transform. Intuitively, we could understand this as noting that there aren't any unique examples in the test set that aren't included in the training set. Thus the laplace transform doesn't resolve any such concerns where a unique situation would cause a probability of 0.
